{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##1 - Building basic functions with numpy"
      ],
      "metadata": {
        "id": "hjzFkr3ERUEB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.1 - sigmoid function, np.exp()\n",
        "First we will implement sigmoid function through math.exp()\n",
        "\n",
        "**Exercise**: Build a function that returns the sigmoid of a real number x. Use math.exp(x) for the exponential function."
      ],
      "metadata": {
        "id": "ams2Yq87Rc3d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "w50PyJorQ4lw"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "def basic_sigmoid(x):\n",
        "  s = 1/(1+math.exp(-x))\n",
        "  return s"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "basic_sigmoid(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcThDAI7RF8C",
        "outputId": "02306c4b-946c-4b79-f36b-20b38cbe5284"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9525741268224334"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We rarely use the \"math\" library in deep learning because the inputs of the functions are real numbers. In deep learning we mostly use matrices and vectors. This is why numpy is more useful."
      ],
      "metadata": {
        "id": "V6PKUX-JSmXj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If x is a row vector, np.exp(x) will apply the exponential function to every element of x."
      ],
      "metadata": {
        "id": "NSgsQXb7SzZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "x = np.array([1,2,3])\n",
        "np.exp(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6YGueBeSNc7",
        "outputId": "a211c5ab-377c-4252-f179-efee762a1076"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2.71828183,  7.3890561 , 20.08553692])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "  s = 1/(1+np.exp(-x))\n",
        "  return s"
      ],
      "metadata": {
        "id": "48jJd10mTFar"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sigmoid(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgHGRjXqTl1x",
        "outputId": "2552e41d-1e96-4afd-afa1-4f35cee66377"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.73105858, 0.88079708, 0.95257413])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.2 - Sigmoid gradient\n",
        "\n",
        "**Exercise**:Implement the function sigmoid_grad() to compute the gradient of the sigmoid function with respect to its input x."
      ],
      "metadata": {
        "id": "mZ_Ia4JYekcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid_gradient(x):\n",
        "  s = sigmoid(x)\n",
        "  ds = s*(1-s)\n",
        "\n",
        "  return ds"
      ],
      "metadata": {
        "id": "5l-Zgh6wTott"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sigmoid_gradient(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1LN6120e8iG",
        "outputId": "05db5b89-46e0-4b9d-cf6a-a689e64d750c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.19661193, 0.10499359, 0.04517666])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.3 - Reshaping arrays\n",
        "\n",
        "Two common numpy functions used in deep learning are np.shape and np.reshape().\n",
        "\n",
        "*   X.shape is used to get the shape (dimension) of a matrix/vector X.\n",
        "*   X.reshape(...) is used to reshape X into some other dimension\n",
        "\n",
        "**Exercise**: Implement image2vector() that takes an input of shape (length, height, 3) and returns a vector of shape (length*height*3, 1). For example, if you would like to reshape an array v of shape (a, b, c) into a vector of shape (a*b,c) you would do:\n",
        "\n",
        "v = v.reshape((v.shape[0]*v.shape[1], v.shape[2])) # v.shape[0] = a ; v.shape[1] = b ; v.shape[2] = c"
      ],
      "metadata": {
        "id": "8DGJkCIohmwg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is a 3 by 3 by 2 array, typically images will be (num_px_x, num_px_y,3) where 3 represents the RGB values\n",
        "image = np.array([[[ 0.67826139,  0.29380381],\n",
        "        [ 0.90714982,  0.52835647],\n",
        "        [ 0.4215251 ,  0.45017551]],\n",
        "\n",
        "       [[ 0.92814219,  0.96677647],\n",
        "        [ 0.85304703,  0.52351845],\n",
        "        [ 0.19981397,  0.27417313]],\n",
        "\n",
        "       [[ 0.60659855,  0.00533165],\n",
        "        [ 0.10820313,  0.49978937],\n",
        "        [ 0.34144279,  0.94630077]]])\n",
        "\n",
        "print(\"Image matrix: \"+str(image))\n",
        "print(\"Image matrix shape: \"+str(image.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHKS5mrbfArg",
        "outputId": "16750243-c3eb-4438-f216-211a41e2bc7c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image matrix: [[[0.67826139 0.29380381]\n",
            "  [0.90714982 0.52835647]\n",
            "  [0.4215251  0.45017551]]\n",
            "\n",
            " [[0.92814219 0.96677647]\n",
            "  [0.85304703 0.52351845]\n",
            "  [0.19981397 0.27417313]]\n",
            "\n",
            " [[0.60659855 0.00533165]\n",
            "  [0.10820313 0.49978937]\n",
            "  [0.34144279 0.94630077]]]\n",
            "Image matrix shape: (3, 3, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def image2vector(img_matrix):\n",
        "  v = img_matrix.reshape(img_matrix.shape[0]*img_matrix.shape[1]*img_matrix.shape[2],1)\n",
        "  return v"
      ],
      "metadata": {
        "id": "R05ekcNUh-fh"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_vector = image2vector(image)\n",
        "print(\"Image vector: \"+str(img_vector))\n",
        "print(\"Image vector shape: \"+str(img_vector.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3kbXN6ojG8r",
        "outputId": "689d4425-cf29-45d0-d5e3-31f70bf00b04"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image vector: [[0.67826139]\n",
            " [0.29380381]\n",
            " [0.90714982]\n",
            " [0.52835647]\n",
            " [0.4215251 ]\n",
            " [0.45017551]\n",
            " [0.92814219]\n",
            " [0.96677647]\n",
            " [0.85304703]\n",
            " [0.52351845]\n",
            " [0.19981397]\n",
            " [0.27417313]\n",
            " [0.60659855]\n",
            " [0.00533165]\n",
            " [0.10820313]\n",
            " [0.49978937]\n",
            " [0.34144279]\n",
            " [0.94630077]]\n",
            "Image vector shape: (18, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.4 - Normalizing rows\n",
        "\n",
        "Another common technique we use in Machine Learning and Deep Learning is to normalize our data. It often leads to a better performance because gradient descent converges faster after normalization. Here, by normalization we mean dividing each row vector of x by its norm.\n",
        "\n",
        "**Exercise**: Implement normalizeRows() to normalize the rows of a matrix. After applying this function to an input matrix x, each row of x should be a vector of unit length (meaning length 1)."
      ],
      "metadata": {
        "id": "Oiy_upxiq7-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalizeRows(x):\n",
        "  x_norm = np.linalg.norm(x,keepdims=True,axis=1)\n",
        "  x = x/x_norm\n",
        "  return x"
      ],
      "metadata": {
        "id": "clmgPTTOo2Wn"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([\n",
        "    [0, 3, 4],\n",
        "    [1, 6, 4]])\n",
        "\n",
        "print(\"Initial matrix: \"+str(x))\n",
        "print(\"Normalized matrix: \"+str(normalizeRows(x)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yr0XGwq6r_1t",
        "outputId": "d073145f-ad88-48fc-98e5-08406de9ac4b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial matrix: [[0 3 4]\n",
            " [1 6 4]]\n",
            "Normalized matrix: [[0.         0.6        0.8       ]\n",
            " [0.13736056 0.82416338 0.54944226]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.5 - Broadcasting and the softmax function\n",
        "A very important concept to understand in numpy is \"broadcasting\". It is very useful for performing mathematical operations between arrays of different shapes.\n",
        "\n",
        "**Exercise**: Implement a softmax function using numpy. You can think of softmax as a normalizing function used when your algorithm needs to classify two or more classes. You will learn more about softmax in the second course of this specialization."
      ],
      "metadata": {
        "id": "q7650lh5tOEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "  x_exp = np.exp(x)\n",
        "  x_sum = np.sum(x_exp,axis=1,keepdims=True)\n",
        "  s = x_exp/x_sum\n",
        "  return s"
      ],
      "metadata": {
        "id": "uqk1m4f4sYow"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([\n",
        "    [9, 2, 5, 0, 0],\n",
        "    [7, 5, 0, 0 ,0]])\n",
        "print(\"Initial matrix: \"+str(x)+\"\\n\")\n",
        "print(\"Exp matrix: \"+str(np.exp(x))+\"\\n\")\n",
        "print(\"Sum matrix: \"+str(np.sum(np.exp(x),axis=1,keepdims=True))+\"\\n\")\n",
        "print(\"softmax(x) = \" + str(softmax(x)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pM97JE8ktvEO",
        "outputId": "7de7c275-8cbe-4756-afbd-5ea63444546d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial matrix: [[9 2 5 0 0]\n",
            " [7 5 0 0 0]]\n",
            "\n",
            "Exp matrix: [[8.10308393e+03 7.38905610e+00 1.48413159e+02 1.00000000e+00\n",
            "  1.00000000e+00]\n",
            " [1.09663316e+03 1.48413159e+02 1.00000000e+00 1.00000000e+00\n",
            "  1.00000000e+00]]\n",
            "\n",
            "Sum matrix: [[8260.88614278]\n",
            " [1248.04631753]]\n",
            "\n",
            "softmax(x) = [[9.80897665e-01 8.94462891e-04 1.79657674e-02 1.21052389e-04\n",
            "  1.21052389e-04]\n",
            " [8.78679856e-01 1.18916387e-01 8.01252314e-04 8.01252314e-04\n",
            "  8.01252314e-04]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2 - Vectorization"
      ],
      "metadata": {
        "id": "olRYgIWAvna6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In deep learning, you deal with very large datasets. Hence, a non-computationally-optimal function can become a huge bottleneck in your algorithm and can result in a model that takes ages to run. To make sure that your code is computationally efficient, you will use vectorization. For example, try to tell the difference between the following implementations of the dot/outer/elementwise product."
      ],
      "metadata": {
        "id": "q92Ne_CUvxa_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "x1 = [9, 2, 5, 0, 0, 7, 5, 0, 0, 0, 9, 2, 5, 0, 0]\n",
        "x2 = [9, 2, 2, 9, 0, 9, 2, 5, 0, 0, 9, 2, 5, 0, 0]\n",
        "\n",
        "### CLASSIC DOT PRODUCT OF VECTORS IMPLEMENTATION ###\n",
        "tic = time.process_time()\n",
        "dot = 0\n",
        "for i in range(len(x1)):\n",
        "    dot+= x1[i]*x2[i]\n",
        "toc = time.process_time()\n",
        "print (\"dot = \" + str(dot) + \"\\n ----- Computation time = \" + str(1000*(toc - tic)) + \"ms\")\n",
        "\n",
        "### CLASSIC OUTER PRODUCT IMPLEMENTATION ###\n",
        "tic = time.process_time()\n",
        "outer = np.zeros((len(x1),len(x2))) # we create a len(x1)*len(x2) matrix with only zeros\n",
        "for i in range(len(x1)):\n",
        "    for j in range(len(x2)):\n",
        "        outer[i,j] = x1[i]*x2[j]\n",
        "toc = time.process_time()\n",
        "print (\"outer = \" + str(outer) + \"\\n ----- Computation time = \" + str(1000*(toc - tic)) + \"ms\")\n",
        "\n",
        "### CLASSIC ELEMENTWISE IMPLEMENTATION ###\n",
        "tic = time.process_time()\n",
        "mul = np.zeros(len(x1))\n",
        "for i in range(len(x1)):\n",
        "    mul[i] = x1[i]*x2[i]\n",
        "toc = time.process_time()\n",
        "print (\"elementwise multiplication = \" + str(mul) + \"\\n ----- Computation time = \" + str(1000*(toc - tic)) + \"ms\")\n",
        "\n",
        "### CLASSIC GENERAL DOT PRODUCT IMPLEMENTATION ###\n",
        "W = np.random.rand(3,len(x1)) # Random 3*len(x1) numpy array\n",
        "tic = time.process_time()\n",
        "gdot = np.zeros(W.shape[0])\n",
        "for i in range(W.shape[0]):\n",
        "    for j in range(len(x1)):\n",
        "        gdot[i] += W[i,j]*x1[j]\n",
        "toc = time.process_time()\n",
        "print (\"gdot = \" + str(gdot) + \"\\n ----- Computation time = \" + str(1000*(toc - tic)) + \"ms\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IjPhtB5usDV",
        "outputId": "dfe51752-15bf-4247-ca1d-240ba8772407"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dot = 278\n",
            " ----- Computation time = 0.12637600000076077ms\n",
            "outer = [[81. 18. 18. 81.  0. 81. 18. 45.  0.  0. 81. 18. 45.  0.  0.]\n",
            " [18.  4.  4. 18.  0. 18.  4. 10.  0.  0. 18.  4. 10.  0.  0.]\n",
            " [45. 10. 10. 45.  0. 45. 10. 25.  0.  0. 45. 10. 25.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [63. 14. 14. 63.  0. 63. 14. 35.  0.  0. 63. 14. 35.  0.  0.]\n",
            " [45. 10. 10. 45.  0. 45. 10. 25.  0.  0. 45. 10. 25.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [81. 18. 18. 81.  0. 81. 18. 45.  0.  0. 81. 18. 45.  0.  0.]\n",
            " [18.  4.  4. 18.  0. 18.  4. 10.  0.  0. 18.  4. 10.  0.  0.]\n",
            " [45. 10. 10. 45.  0. 45. 10. 25.  0.  0. 45. 10. 25.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
            " ----- Computation time = 0.39079900000160706ms\n",
            "elementwise multiplication = [81.  4. 10.  0.  0. 63. 10.  0.  0.  0. 81.  4. 25.  0.  0.]\n",
            " ----- Computation time = 0.18110900000323227ms\n",
            "gdot = [22.20714919 23.65694861 22.54507771]\n",
            " ----- Computation time = 0.2143439999997554ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = [9, 2, 5, 0, 0, 7, 5, 0, 0, 0, 9, 2, 5, 0, 0]\n",
        "x2 = [9, 2, 2, 9, 0, 9, 2, 5, 0, 0, 9, 2, 5, 0, 0]\n",
        "\n",
        "### VECTORIZED DOT PRODUCT OF VECTORS ###\n",
        "tic = time.process_time()\n",
        "dot = np.dot(x1,x2)\n",
        "toc = time.process_time()\n",
        "print (\"dot = \" + str(dot) + \"\\n ----- Computation time = \" + str(1000*(toc - tic)) + \"ms\")\n",
        "\n",
        "### VECTORIZED OUTER PRODUCT ###\n",
        "tic = time.process_time()\n",
        "outer = np.outer(x1,x2)\n",
        "toc = time.process_time()\n",
        "print (\"outer = \" + str(outer) + \"\\n ----- Computation time = \" + str(1000*(toc - tic)) + \"ms\")\n",
        "\n",
        "### VECTORIZED ELEMENTWISE MULTIPLICATION ###\n",
        "tic = time.process_time()\n",
        "mul = np.multiply(x1,x2)\n",
        "toc = time.process_time()\n",
        "print (\"elementwise multiplication = \" + str(mul) + \"\\n ----- Computation time = \" + str(1000*(toc - tic)) + \"ms\")\n",
        "\n",
        "### VECTORIZED GENERAL DOT PRODUCT ###\n",
        "tic = time.process_time()\n",
        "dot = np.dot(W,x1)\n",
        "toc = time.process_time()\n",
        "print (\"gdot = \" + str(dot) + \"\\n ----- Computation time = \" + str(1000*(toc - tic)) + \"ms\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpTT7_R-wp-r",
        "outputId": "e5b23af5-c03e-4ccc-ff8a-90bf763834d2"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dot = 278\n",
            " ----- Computation time = 0.227711999997382ms\n",
            "outer = [[81 18 18 81  0 81 18 45  0  0 81 18 45  0  0]\n",
            " [18  4  4 18  0 18  4 10  0  0 18  4 10  0  0]\n",
            " [45 10 10 45  0 45 10 25  0  0 45 10 25  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [63 14 14 63  0 63 14 35  0  0 63 14 35  0  0]\n",
            " [45 10 10 45  0 45 10 25  0  0 45 10 25  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [81 18 18 81  0 81 18 45  0  0 81 18 45  0  0]\n",
            " [18  4  4 18  0 18  4 10  0  0 18  4 10  0  0]\n",
            " [45 10 10 45  0 45 10 25  0  0 45 10 25  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            " ----- Computation time = 0.2058100000006391ms\n",
            "elementwise multiplication = [81  4 10  0  0 63 10  0  0  0 81  4 25  0  0]\n",
            " ----- Computation time = 0.11779400000122564ms\n",
            "gdot = [22.20714919 23.65694861 22.54507771]\n",
            " ----- Computation time = 0.15634900000094376ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.1 Implement the L1 and L2 loss functions\n",
        "**Exercise**: Implement the numpy vectorized version of the L1 loss. You may find the function abs(x) (absolute value of x) useful."
      ],
      "metadata": {
        "id": "AjRj_r0vxTQD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def L1loss(yhat,y):\n",
        "  return sum(abs(yhat-y))\n",
        "\n",
        "def L2loss(yhat,y):\n",
        "  return np.dot(yhat-y,yhat-y)"
      ],
      "metadata": {
        "id": "BSPOdk_1w3oM"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = np.array([.9, 0.2, 0.1, .4, .9])\n",
        "y = np.array([1, 0, 0, 1, 1])"
      ],
      "metadata": {
        "id": "q9b6qKMyxmcP"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"L1 loss: \"+str(L1loss(yhat,y)))\n",
        "print(\"L2 loss: \"+str(L2loss(yhat,y)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCt8JaKOyAkD",
        "outputId": "98a2fbeb-8d59-4433-d003-ea198eb4be7d"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L1 loss: 1.1\n",
            "L2 loss: 0.43\n"
          ]
        }
      ]
    }
  ]
}